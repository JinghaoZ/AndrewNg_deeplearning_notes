{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. object localization\n",
    "    * image classification -> classification with localization -> detection\n",
    "    * 在图像分类时，神经网络通过softmax可以输出一个图片属于哪一类，这时图片上没有其他物体，比如\n",
    "        1. 输出类别为行人、汽车、摩托车、背景\n",
    "        2. 使用softmax来判断属于哪一类\n",
    "        3. 每一张图片只有一个物体， 即只属于一类\n",
    "    * 在物体定位时\n",
    "        1. 令NN多输出四个参数，分表表示框出物体中心和长宽，如图，(bx, by, bh, bw) = (0.5, 0.7, 0.3, 0.4)  \n",
    "        <img src=\"定位.png\" width=\"200\">\n",
    "    * 如何定义目标标签y\n",
    "        1. 需要输出(bx, by, bh, bw)以及类型(1-4)\n",
    "        2. y = $[P_c, bx, by, bh, bw, c_1, c_2, c_3]$\n",
    "            1. 其中$p_c$表示图片是否有物体，如果是背景那么为0， 否则为1\n",
    "            2. bx, by, bh, bw,表示物体的位置参数\n",
    "            3. c_i 表示实际上属于哪一类物体\n",
    "        3. loss function\n",
    "            1. square loss: $L(\\hat{y}, y) = \\sum_{i=1}^{m}(\\hat{y}_i - y_i)^2$ if $p_c = 1$ else $(\\hat{y}_0 - y_0)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Landmark Detection\n",
    "    1. 人脸/人形态特征点检测\n",
    "        * 通过CNN输出各个特征点的位置\n",
    "        * 输出为$[p_c, lx_1, ly_1, ..., lx_n, ly_n], p_c$表示是否有面部/人体，(lx, ly)表示各个特征点的位置。\n",
    "        * 每个特征点的表示的相对人体的位置应该相同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Object Detection\n",
    "    1. 物体检测用来圈出一张图片的所有目标对象\n",
    "    2. Sliding windows detection\n",
    "        * 通过将图片用滑动窗口分割，判断每个窗口内是否存在一个目标对象\n",
    "        * 可以根据滑动的strides来控制遍历速度\n",
    "        * 改变窗口大小，以固定stride重新遍历\n",
    "        * 通过以上方法，尽量获得所有物体"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Turning FC layer into conv layer \n",
    "    1. 经过池化后的layer，可以使用卷积来代替全连接，即使用多个与上一层相同大小的卷积核，将上一层转化为一维tensor\n",
    "    2. 滑动窗口的卷积实现\n",
    "        * 假设训练集图片像素为$14*14*3$, (训练集是单分类，每张图片只有一个物体) 有  \n",
    "        <img src=\"slidewindow.png\" width=\"700\">\n",
    "        * 假设测试集像素为$16*16*3$, （测试集是多物体图片）那么  \n",
    "        <img src=\"slidewindowstest.png\" width=\"700\">  \n",
    "        图中windows大小为$14*14$（和训练集相同），步长为1， 因此最后得到四个windows，size=$2*2$\n",
    "        * 假设测试集2大小为$28*28*3$，滑动窗口大小为$14*14$，步长为2，最终得到$8*8$的输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bounding box predictions\n",
    "    1. 滑动窗口的缺陷\n",
    "        * 有可能任意一个窗口都不能完全贴合整个物体\n",
    "    2. YOLO算法\n",
    "        * 首先将图片用网格分割\n",
    "        * 使用图像分类和物体检测对处理每个网格\n",
    "        * 假设以$3*3$网格分割，那么每个部分输出一个长度为8的向量$(p_c, b_i, c_i)$，总共输出$3*3*8$的向量\n",
    "        * 物体的位置应该为物体在每个格子中的位置\n",
    "    3. label向量的编码\n",
    "        * 标记位和滑动窗口相同\n",
    "        * 将左上角标记位(0, 0), 右下角为(1, 1), 则$b_x, b_y, b_w, b_h$为目标物体相对于网格的位置, 其中中心点坐标$(b_x, b_y)$必须介于(0, 1), 而长宽标记可以大于1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Evaluation\n",
    "     1. 交并比(Intersection on union, IOU)\n",
    "         * 交并比表示预测框架与实际框架相交部分与预测框架的面积的比值\n",
    "         * 当IOU > 0.5时表示框架正确"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Non-max suppression 非极大值抑制\n",
    "    1. 当多个网格分割了同一个物体时($b_w, b_h$两个参数大于1)，需要选出物体中心点真实所在的网格\n",
    "        * 首先选择$p_c$最大的网格，视为真正的物体中心所在网格，获得其框架参数b，将框架高亮\n",
    "        * 非极大值抑制会抑制那些与高亮框架交并比最大的框架\n",
    "    2. 使用方法\n",
    "        * 去掉$p_c \\leq 0.6$的所有框架\n",
    "        * 对于剩下的框架\n",
    "            1. 选出$p_c$最大的框架作为预测值\n",
    "            2. 去掉与预测值$IoU \\geq 0.5$的所有框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Anchor Boxes\n",
    "    1. 当试图用一个网格识别出多个物体时，可以使用anchor boxes\n",
    "    2. anchor boxes通过事先定义两个不同shape的box，然后分别识别不同的物体\n",
    "    3. 使用anchor boxes后，输出y会扩充至n个anchor boxes的shape\n",
    "        * 例如，假设有3* 3的网格，输出长度为8，即输出为3* 3* 8，那么在使用两个anchor box的时候，输出变为3* 3* 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
